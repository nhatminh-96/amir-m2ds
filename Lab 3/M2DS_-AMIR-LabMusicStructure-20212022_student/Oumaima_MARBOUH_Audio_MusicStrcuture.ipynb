{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX4gaUt3WAWz"
   },
   "source": [
    "# Lab/ Audio/ Music Structure Discovery (MSD) / Boundaries Detection \n",
    "\n",
    "- Author: geoffroy.peeters@telecom-paris.fr\n",
    "- Date: 2022/01/31\n",
    "- Version: 1.0\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of this goal is to create a system to perform Music Structure Discovery (MSD), i.e. segmenting a music track into its various verses, chorus, briges, ...\n",
    "\n",
    "MSD systems usually perform two tasks\n",
    "- (a) Estimating the **segments** of the music track\n",
    "- (b) **Labeling** each estimated segments, i.e. deciding which segments is a repetition of another one\n",
    "\n",
    "We will focus on the segmentation task for this lab.\n",
    "\n",
    "To estimate the segments you will perform the following steps\n",
    "- (1) Extracting audio features for the music track; you will extract here both Chroma and MFCC\n",
    "- (2) Compute the corresponding Self-Similarity-Matrix (SSM) using a cosine-distance: one SSM for the Chroma; one SSM for the MFCC\n",
    "- (3) Combine the two SSMs \n",
    "- (4) Compute the novelty-score proposed by Jonathan Foote, by convolving the combined SSMs with a checker-board kernel\n",
    "- (5) Detect the local peaks of the novelty-score by applying a peak-picking algorithm\n",
    "- (6) Measure the performances of the developped algorithm for one track of the SALAMA dataset.\n",
    "\n",
    "For (1) you will use the **librosa** package, which is (currently) the most used python package for music and audio analysis. It has been developped by Columbia University and New-York University.\n",
    "https://librosa.org/doc/latest/index.html.\n",
    "\n",
    "For (6) you will use the **mir_eval** package which is (currently) the most used python package to evaluate the performances of Music Information Retrieval (MIR) algorithms. https://craffel.github.io/mir_eval/\n",
    "\n",
    "## Your task:\n",
    "\n",
    "In the following the main code (global architecture) is provided as well as the results you have to find.\n",
    "Your task is to fill in the missing parts in the code; i.e. the parts between ```# --- START CODE HERE``` and ```# --- END CODE HERE```)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLIg9rzCWAW5"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vmVE6A6WDvT",
    "outputId": "dd0b0dd8-3c3a-42be-d323-aac6c711dbd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mir_eval in c:\\users\\_minh_\\anaconda3\\lib\\site-packages (0.7)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\_minh_\\anaconda3\\lib\\site-packages (from mir_eval) (1.7.1)\n",
      "Requirement already satisfied: six in c:\\users\\_minh_\\anaconda3\\lib\\site-packages (from mir_eval) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in c:\\users\\_minh_\\anaconda3\\lib\\site-packages (from mir_eval) (1.20.3)\n",
      "Requirement already satisfied: future in c:\\users\\_minh_\\anaconda3\\lib\\site-packages (from mir_eval) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05V4hVbnWN8Y",
    "outputId": "800e25c3-29fe-4804-d2fa-0293de506d9f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14508/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "SMMwBOUAWAW7",
    "outputId": "40e05f53-ef81-42f9-f0b5-10b4b40aeed7"
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-z4JGgGWhfd",
    "outputId": "ada8dde7-8489-4e5c-c242-473a31cf6433"
   },
   "outputs": [],
   "source": [
    "cd drive/MyDrive/M2DS_-AMIR-LabMusicStructure-20212022_student/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDWAAkvQeje4",
    "outputId": "4e959acf-67da-49dd-d04d-6ccbb8a1e6c3"
   },
   "outputs": [],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FGmpXjIYWAW_",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import librosa\n",
    "import mir_eval\n",
    "\n",
    "import tools_structure\n",
    "\n",
    "do_student = True\n",
    "\n",
    "audio_file = './audio.mp3' \n",
    "annot_file = './textfile1_lowercase.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fILYL_tOWAXB"
   },
   "source": [
    "# Extract audio features\n",
    "\n",
    "From the audio file we will first compute the audio features.\n",
    "\n",
    "As proposed in [Peeters, ISMIR, 2017], the music structure can either comes \n",
    "- from variations of the harmonic (melody, chords) content or \n",
    "- from variations of the timbre (instrumentation) content. \n",
    "\n",
    "In order to take both into account, we will therefore extract both Chroma and MFCC features.\n",
    "\n",
    "You will do so by using the **librosa** package. \n",
    "You will use the default values for the parametrization of the Chroma and MFCC; but will use the given hop_length, and will use the CQT algorithm for the Chroma computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LieNvUvLWAXD"
   },
   "outputs": [],
   "source": [
    "def F_extract_features(audio_file, hop_length):\n",
    "    \"\"\"\n",
    "    description:\n",
    "        Compute the Chroma and MFCC features of the given audio_file\n",
    "    inputs:\n",
    "        - audio_file: full-path to the audio file\n",
    "        - hop_length: hop_length to be used for the analysis in samples\n",
    "    outputs:\n",
    "        - chroma_m (nb_dim, nb_frame) numpy matrix containing the Chroma over frames\n",
    "        - mfcc_m (nb_dim, nb_frame) numpy matrix containing the MFCC over frames\n",
    "        - time_sec_v (nb_frame) numpy vector containing the position of the analysis frames in second\n",
    "    \"\"\"\n",
    "    if do_student:\n",
    "        audio_v, sr_hz = librosa.load(audio_file)\n",
    "        chroma_m=librosa.feature.chroma_cqt(y =audio_v,hop_length=hop_length)\n",
    "        mfcc_m=librosa.feature.mfcc(y=audio_v,hop_length=hop_length)\n",
    "        #time_sec_v=np.array([k*hop_length for k in range(chroma_m.shape[1])])\n",
    "        #time_sec_v = np.linspace(\n",
    "        #    0, chroma_m.shape[1] * hop_length / sr_hz, \n",
    "        #    num=chroma_m.shape[1], endpoint=True\n",
    "        #)\n",
    "        time_sec_v = np.arange(0, audio_v.shape[0], hop_length)/sr_hz\n",
    "    \n",
    "    return chroma_m, mfcc_m, time_sec_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmkvs46oWAXE"
   },
   "source": [
    "### Test\n",
    "\n",
    "You should obtain the following values\n",
    "```\n",
    "(12, 6767)\n",
    "(20, 6767)\n",
    "(6767,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXOMnxfiWAXG",
    "outputId": "7a7dbf28-97a1-4729-922c-3006034bda1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\_Minh_\\AppData\\Local\\Temp/ipykernel_14508/3661468344.py:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_v, sr_hz = librosa.load(audio_file)\n"
     ]
    }
   ],
   "source": [
    "chroma_m, mfcc_m, time_sec_v = F_extract_features(audio_file, hop_length=1024)\n",
    "print(chroma_m.shape)\n",
    "print(mfcc_m.shape)\n",
    "print(time_sec_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2qcj8zHWAXH"
   },
   "source": [
    "## Reducing the number of data\n",
    "\n",
    "To represent a whole music track of 4 minutes, we need over 6767 frames.\n",
    "The corresponding Self-Similarity-Matrix (SSM) would have an enormous size (6767*6767). \n",
    "\n",
    "We therefore reduce the amount of data.\n",
    "We do this by performing a statistical-aggregation (by mean and std) of the feature behavior over time. \n",
    "We perform a sliding analysis (with a specific window duration and hop-size) over each dimension of the MFCC and Chroma features.\n",
    "\n",
    "```\n",
    "(24, 1352)\n",
    "(40, 1352)\n",
    "(1352,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nt61fNZWAXJ",
    "outputId": "46f55e46-f1ee-4186-bee1-7c44d336514a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp, chroma_m = tools_structure.F_reduce_time(time_sec_v, chroma_m)\n",
    "time_sec_v, mfcc_m = tools_structure.F_reduce_time(time_sec_v, mfcc_m)\n",
    "print(chroma_m.shape)\n",
    "print(mfcc_m.shape)\n",
    "print(time_sec_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uihJDvvWAXK"
   },
   "source": [
    "# Compute Self-Similarity Matrix\n",
    "\n",
    "For each of the features (MFCC or Chroma) you will compute the corresponding Self-Similarity Matrix (SSM) using the cosine-distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoAKd454WAXL"
   },
   "outputs": [],
   "source": [
    "import scipy.spatial \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def F_compute_SSM(features_m):\n",
    "    \"\"\"\n",
    "    descriptions:\n",
    "        compute Self-Similarity-Matrix (SSM) from audio feature matrix using cosine-distance.\n",
    "    inputs:\n",
    "        - features_m (nb_dim, nb_frame)\n",
    "    outputs:\n",
    "        - SSM_m (nb_frame, nb_frame)\n",
    "    \"\"\"\n",
    "    \n",
    "    if do_student:\n",
    "      SSM_m = cosine_similarity(features_m.T, features_m.T, dense_output=False)\n",
    "            \n",
    "    return SSM_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qw6kSgYtWAXM"
   },
   "outputs": [],
   "source": [
    "SSMchroma_m = F_compute_SSM(chroma_m)\n",
    "SSMmfcc_m = F_compute_SSM(mfcc_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i26c-oTrWAXN"
   },
   "source": [
    "We apply some magical processing (as proposed in [Peeters, ISMIR, 2007]) to make the SSM matrices more beautifull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "6BBu4pSfWAXO",
    "outputId": "634d1b51-9403-44a4-d8fb-abd990c80280",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SSMchroma_m = tools_structure.F_stretch_ssm(SSMchroma_m)\n",
    "SSMmfcc_m = tools_structure.F_stretch_ssm(SSMmfcc_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2rvLY7uuoBt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmtsE76OWAXP"
   },
   "source": [
    "We finally combine both the MFCC SSM matrix and the Chroma SSM matrix. You can try various values of the alpha parameters to highlight more harmonic structure (alpha=1) or timbre structure (alpha=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eQfigBVWAXP"
   },
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "SSM_m = alpha*SSMchroma_m + (1-alpha)*SSMmfcc_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW9eiww0WAXQ"
   },
   "source": [
    "### Test \n",
    "\n",
    "You should obtain the following figure for the SSM.\n",
    "<img src=./lab_structure_ssm-combined.png width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "wWPA4sHfWAXQ",
    "outputId": "68f14c53-9975-4d99-8c6b-7ce00bb0e7a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(SSM_m, aspect='equal', cmap=cm.inferno);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0PAF9JJWAXR",
    "scrolled": true
   },
   "source": [
    "# Segmentation: checkerboard-kernel, novelty score\n",
    "\n",
    "We now perform the segmentation of the music track by convolving its SSM with a checker-board kernel as proposed by [Foote, ICME, 2000].\n",
    "\n",
    "\n",
    "We first created the checkerboard kernel ``C_m``. \n",
    "It is defined by \n",
    "$$C(m,n) = sign(m) \\cdot sign(n) \\cdot e^{-\\frac{m^2+n^2}{2\\sigma^2}}$$\n",
    "for $m, n \\in \\{-L,\\ldots, L-1\\}$.\n",
    "The size of the kernel is $(2L, 2L$.\n",
    "$\\sigma$ is the standard-deviation of the Gaussian window used to smooth the borders of checkerboard kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFIXzECtrkAN"
   },
   "outputs": [],
   "source": [
    "def F_sign(n: int):\n",
    "    if n < 0:\n",
    "        return -1\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RU671XPzWAXS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def F_checkerboard_kernel(L=10, sigma=5, do_affiche=True):\n",
    "\n",
    "    if do_student:\n",
    "        m_v, n_v = np.arange(-L, L), np.arange(-L, L)\n",
    "        C = np.array(\n",
    "            [F_sign(m) * np.exp(-(m ** 2) / (2 * sigma ** 2))  for m in m_v]\n",
    "        ).reshape(-1, 1)\n",
    "        C_m = C @ C.T\n",
    "                \n",
    "\n",
    "    if do_affiche:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        X, Y = np.meshgrid(m_v, n_v)\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.plot_surface(X, Y, C_m, cmap=cm.inferno)\n",
    "        ax.set_xlabel('m')\n",
    "        ax.set_ylabel('n')\n",
    "        ax.view_init(50, -20)\n",
    "    return C_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mJL62cLWAXS"
   },
   "source": [
    "### Test \n",
    "\n",
    "You should obtain the following figure for the checkerboard kernel.\n",
    "<img src=./lab_structure_kernel.png width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "f-btgHaUWAXT",
    "outputId": "b25fd7ba-45b6-4546-db1c-aee1d8784ff6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C_m = F_checkerboard_kernel(L=50, sigma=20, do_affiche=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hagy2_kuWAXT"
   },
   "source": [
    "We now convolve our combined SSM matrix ``SSM_m`` with our checkerboard kernel ``C_m``. You can use ``scipy`` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffexEvMrWAXU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_student:\n",
    "    filtered_SSM_m = convolve2d(SSM_m, C_m, mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sSZuznWAXU"
   },
   "source": [
    "The novelty curve ``novelty_v`` are the values of the convolved matrix ``filtered_SSM_m`` along its main diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2PI__uGWAXU"
   },
   "outputs": [],
   "source": [
    "if do_student:\n",
    "    novelty_v = filtered_SSM_m.diagonal()\n",
    "    # novelty_v = np.array([filtered_SSM_m[i,i] for i in range(filtered_SSM_m.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCdg3npxWAXV"
   },
   "source": [
    "### Test \n",
    "\n",
    "You should obtain the following figures for the resulting convolution and novelty curve.\n",
    "<img src=./lab_structure_convolved.png width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "0_q5eEpAWAXV",
    "outputId": "1fe616a8-eeb4-4f86-8403-f095976d8d86",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "nb_frame = len(novelty_v)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(SSM_m, aspect='auto', cmap=cm.inferno);\n",
    "plt.plot(novelty_v/np.max(novelty_v)*nb_frame, 'w');\n",
    "plt.xlim([0, nb_frame]); plt.ylim([nb_frame, 0])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(filtered_SSM_m, aspect='auto', cmap=cm.inferno);\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(C_m, aspect='auto', cmap=cm.inferno);\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(novelty_v);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHn6XEHiWAXW"
   },
   "source": [
    "## Detect the peaks of the novelty curve\n",
    "\n",
    "Peaks in the novelty curve indicates large changes between the part on the left of the peak and the part of the right of the peak; hence they indicates large structural changes in the music track.\n",
    "\n",
    "To detect the peaks in the novelty function we will use a method inspired by the ones of (but improved) [MacCallumn, ICASSP, 2019].\n",
    "\n",
    "We denote by $\\eta(\\nu)$ the novelty function over time $\\nu$.\n",
    "\n",
    "A peak is defined by \n",
    "\n",
    "(1) a value $\\mu$ which is larger than its **local average** value by a factor $\\tau$ (the threshold). This **local average** value is compute over a window centered on $\\nu$ and which extends over $[\\nu-T, \\nu+T]$.\n",
    "\n",
    "$$\\frac{\\eta(\\nu)}{\\frac{1}{2T+1}\\sum_{t=\\nu-T}^{\\nu+T}\\eta(t)} > \\tau$$\n",
    "\n",
    "(2) In order to prevent detecting several neighboring peaks, we also requires that the specific $\\mu$ is at the position of the local maximum over $[\\nu-T, \\nu+T]$, i.e. $$\\nu = \\arg\\max_{t \\in [\\nu-T, \\nu+T]} \\eta(t)$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nq-b1sEWAXW"
   },
   "outputs": [],
   "source": [
    "def F_peak_picking(novelty_v, T=30, tau=1.3):\n",
    "    \"\"\"\n",
    "    description:\n",
    "        - detect the peaks (performs peak-picking) of the novelty curve as described in the text above\n",
    "    inputs:\n",
    "        - novelty (nb_frame): numpy array containing the novelty function\n",
    "        - T: defines the size of the interval [nu-T, nu+T] over which the mean value is computed\n",
    "        - tau: defines the threshold\n",
    "    outputs:\n",
    "        - peaks_l: provides the list of boundary **positions** \n",
    "        - mean_v (nb_frame): numpy array containing  the local running average of novelty_v using T \n",
    "    \"\"\"\n",
    "    if do_student:\n",
    "        nb_frame = len(novelty_v)\n",
    "        \n",
    "        peaks_s = set()\n",
    "        mean_v = np.zeros(nb_frame)\n",
    "        for mid in range(T, nb_frame - T):\n",
    "            left, right = mid - T, mid + T\n",
    "            mean_v[mid] = np.mean(novelty_v[left: right])\n",
    "            if novelty_v[mid] / mean_v[mid] > tau and mid == left + np.argmax(novelty_v[left: right]):\n",
    "                peaks_s.add(mid)\n",
    "        \n",
    "        peaks_l = list(peaks_s)\n",
    "    return peaks_l, mean_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8AihiLaWAXX"
   },
   "outputs": [],
   "source": [
    "peaks_l, mean_v = F_peak_picking(novelty_v)\n",
    "\n",
    "# --- For proper comparison with the ground-truth annotation, we need to add a boundaries \n",
    "# --- at the beginning and ending of the music track\n",
    "peaks_l.append(0)\n",
    "peaks_l.append(len(novelty_v)-1)\n",
    "estimated_boundaries_l = time_sec_v[ sorted(peaks_l) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Isi4YLFfWAXX"
   },
   "source": [
    "### Test\n",
    "\n",
    "You should obtain the following boundaries\n",
    "\n",
    "```\n",
    "[2.08979592e-01 1.36765533e+01 2.52865306e+01 3.92185034e+01\n",
    " 5.24538776e+01 6.96366440e+01 7.96212245e+01 9.30887982e+01\n",
    " 1.08878367e+02 1.18630748e+02 1.44869297e+02 1.60194467e+02\n",
    " 1.84343220e+02 1.95256599e+02 2.23817143e+02 2.37284717e+02\n",
    " 2.50984490e+02 2.65613061e+02 2.76990839e+02 2.90226213e+02\n",
    " 3.04622585e+02 3.13910567e+02]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iw2ujBZ6WAXX",
    "outputId": "400fb16e-11fb-4575-9014-54dc6c8ae93f"
   },
   "outputs": [],
   "source": [
    "print(estimated_boundaries_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hNDuPUbWAXY"
   },
   "source": [
    "# Estimate the quality of the detected segment boundaries\n",
    "\n",
    "We now measure the performance of our system.\n",
    "\n",
    "For this, we will compare our estimated boundaries to the ground-truth segment boundaries on a music track from the SALAMI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GL8MTuPYWAXY"
   },
   "outputs": [],
   "source": [
    "# --- Loading the ground-truth annotations\n",
    "annot_l = tools_structure.F_get_structure_annot(annot_file)\n",
    "annotated_boundaries_l = np.asarray([a[0] for a in annot_l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRA8xr2GWAXZ"
   },
   "source": [
    "### Test \n",
    "\n",
    "You should obtains segmentations similar to the following figure.\n",
    "<img src=./lab_structure_segments.png width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "p-NrxBmYWAXa",
    "outputId": "5cebc47e-96b9-4237-f694-95375d485dd5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(time_sec_v, novelty_v, 'k');\n",
    "plt.plot(time_sec_v, mean_v, 'k--');\n",
    "for e in estimated_boundaries_l:\n",
    "    plt.plot([e, e], [0, np.max(novelty_v)], 'r');\n",
    "for a in annotated_boundaries_l:\n",
    "    plt.plot([a, a], [0, np.max(novelty_v)], 'g--');\n",
    "plt.xlabel('Time [sec]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtOXPXqBWAXa"
   },
   "source": [
    "# Measuring the performances\n",
    "\n",
    "To quantify the performances of our system we will compare the estimation and the ground-truth annotations using the Precision, Recall and F-Measure.\n",
    "We will do so by defining a tolerance window (around the annotations) of 0.5 second and 3 second. \n",
    "\n",
    "You will will use the **mir_eval** python package for this. This package provides the performance measures for all MIR tasks (including segment boundaries detection).\n",
    "\n",
    "```\n",
    "import mir_eval\n",
    "mir_eval.***\n",
    "```\n",
    "\n",
    "You will find the documentation here:\n",
    "https://craffel.github.io/mir_eval/#mir_eval.segment.detection\n",
    "\n",
    "You can optimize the parameters of the peak-picking function for the two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIgdbCbkWAXa"
   },
   "outputs": [],
   "source": [
    "# --- To be able to use mir_eval, we should first convert the segment boundaries to segments start and stop\n",
    "annotated_segment_m = tools_structure.F_boundaries_to_segments(annotated_boundaries_l)\n",
    "estimated_segment_m = tools_structure.F_boundaries_to_segments(estimated_boundaries_l)\n",
    "\n",
    "if do_student:\n",
    "    Precision05, Recall05, Fmeasure05 = mir_eval.segment.detection(\n",
    "        annotated_segment_m, estimated_segment_m, window=0.5\n",
    "    )\n",
    "    Precision3, Recall3, Fmeasure3 = mir_eval.segment.detection(\n",
    "        annotated_segment_m, estimated_segment_m, window=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeciiFPSWAXb"
   },
   "source": [
    "### Test\n",
    "\n",
    "You should have the following values\n",
    "```\n",
    "at 0.5 second: \t Precision 0.2727272727272727, Recall 0.24, F-Measure0.2553191489361702\n",
    "at 3 second: \t Precision 0.8636363636363636, Recall 0.76, F-Measure0.8085106382978724\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsCExSPiWAXb",
    "outputId": "4054811f-e6b8-4466-959b-1fda384c115d"
   },
   "outputs": [],
   "source": [
    "print('at 0.5 second: \\t Precision {}, Recall {}, F-Measure{}'.format(Precision05, Recall05, Fmeasure05))\n",
    "print('at 3 second: \\t Precision {}, Recall {}, F-Measure{}'.format(Precision3, Recall3, Fmeasure3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSgEE_S1WAXc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Audio_MusicStrcuture_Oumaima_MARBOUH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
