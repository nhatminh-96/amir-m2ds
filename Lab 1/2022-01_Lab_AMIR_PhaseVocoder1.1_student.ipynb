{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab / M2-DS / AMIR / Phase Vocoder\n",
    "\n",
    "- Author: geoffroy.peeters@telecom-paris.fr\n",
    "- Date: 2022/01/17\n",
    "- Version: 1.1 (switch to English, pythonify code)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "The goal of this Lab is to become familiar with audio signal processing in the frequency domain, in particular using the Short Term Fourier Transform (STFT).\n",
    "\n",
    "The Lab will be carried out in Python.\n",
    "The aim will be to program cleanly.\n",
    "This includes \n",
    "- The subdivision of the main problem to be solved into sub-problems. Each sub-problem is written as a function/method/class (especially when these functions/methods are to be used more than once),\n",
    "- the use of variable names and function/method names that clearly indicate their content or functionality,\n",
    "- the documentation of the written code.\n",
    "\n",
    "The goal of this Lab is to perform the complete processing chain: STFT + denoising + phase-vocoder (time stretching without changing the frequency) + inverse STFT.\n",
    "\n",
    "Audio (.wav) signals can be read from files using ```scipy.io.wavfile.read```.\n",
    "The resulting denoised time-stretched audio signal will be written in a file using ```scipy.io.wavfile.write```.\n",
    "\n",
    "In case the audio signal is stereo (2 channels), we will use the mean value over the two channels using the function ```np.mean```.\n",
    "\n",
    "## Your task:\n",
    "\n",
    "In the following the main code (global architecture) is provided.\n",
    "Your task is to fill in the missing parts in the code; i.e. the parts between ```# --- START CODE HERE``` and ```# --- END CODE HERE```).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages, parameters and define generic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import IPython.display as ipd\n",
    "\n",
    "import ipdb\n",
    "\n",
    "\n",
    "audio_file = './speech_noise.wav'\n",
    "do_student = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextpow2(i):\n",
    "    \"\"\"\n",
    "    Find 2^n that is equal to or greater than.\n",
    "    \"\"\"\n",
    "    n = 1\n",
    "    while n < i:\n",
    "        n *= 2\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_plot1(x_v, y_v, labelX, labelY):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,6));\n",
    "\n",
    "    plt.plot(x_v, y_v);\n",
    "    plt.xlabel(labelX); plt.ylabel(labelY)\n",
    "    plt.grid(True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_plot2(data_m, col_v=np.zeros(0), row_v=np.zeros(0), labelCol='', labelRow=''):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,6));\n",
    "\n",
    "    if len(col_v) == 0:\n",
    "        col_v = np.arange(0, data_m.shape[0])\n",
    "    if len(row_v) == 0:\n",
    "        row_v = np.arange(0, data_m.shape[1])\n",
    "\n",
    "    plt.imshow(data_m, origin='lower', aspect='auto', extent=[row_v[0], row_v[-1], col_v[0], col_v[-1]], interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.set_cmap('gray_r')\n",
    "    plt.xlabel(labelRow); plt.ylabel(labelCol)\n",
    "    plt.grid(True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_to_log(X_m):\n",
    "    \"\"\"\n",
    "    apply log and clip at threshold a spectral representation\n",
    "    \"\"\"\n",
    "    logX_m = np.log(X_m)\n",
    "    T = np.max(logX_m)-10\n",
    "    logX_m[logX_m<T]=T\n",
    "    return logX_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step: compute STFT from audio and compute audio from STFT\n",
    "\n",
    "Since all of the following processings are based on the STFT analysis and audio re-synthesis is performed using inverse STFT, we will start by implementing these two features\n",
    "- ```C_stft```: a class that calculates the STFT from the audio signal. Writting a class (and not a function) will allow us to store all necessary information for further processings.\n",
    "- ```F_inverse_stft```: a function that computes the audio signal from its complex STFT (stored as a matrix containing the complex spectra at each analysis time)Ã  using overlap-add algorithm (inverse STFT).\n",
    "\n",
    "We ask you to write the code to compute the STFT, i.e. to write the code that will perform a loop over frame, windowing the audio signal, compute the DFT and store it in a matrix.\n",
    "You should **not** use a function with a pre-build STFT (such as ```scipy.signal.stft```).\n",
    "Writting the code yourself will actually help you being familiar with the process and allows you to write easely the inverse stft code.\n",
    "\n",
    "You will use \n",
    "- a hanning window of length ```L_sec=60``` ms\n",
    "    - Question: How do you calculate the size of the window in samples ```L_n```?\n",
    "- a hop size (distance between two successive frames) ```STEP_sec``` equal to 1/3 of the window length: ```STEP_sec=20```ms\n",
    "- a number of DFT points ```N``` equal to **four time** the first power of 2 greater than ```L_n```\n",
    "    - you will use the function ``nextpow2``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get STFT from the audio signal\n",
    "\n",
    "Class to be written ```C_stft```\n",
    "\n",
    "**Allocation**\n",
    "- Compute the number of frames ```nb_frame``` that is necessary to represent the signal length\n",
    "    - This number depends on the length of the audio signal in samples ```LT_n```, of the window size in samples ```L_n``` and of the hop size in samples ```STEP_n```.\n",
    "        - Question: What is this formula?\n",
    "- Allocate the ``X_im`` matrix of size ```(N/2+1, nb_frame)``` into which the complex spectrum vectors will be stored at each frame\n",
    "    - Note: only the positive half-axis of the DFT (from 0 to ```N/2```) will be stored\n",
    "        - All processing will be done on the positive half-axis\n",
    "\n",
    "**Loop**\n",
    "- Create a loop from 0 to ```nb_frame-1``` advancing over time by ```STEP_n``` samples\n",
    "    - take an audio signal of duration equal to ```L_n```\n",
    "    - multiply it the analysis window\n",
    "    - calculate its DFT of size ```N``` using the function ```np.fft.rfft```\n",
    "    - we keep only the positive half-axis of the DFT (this is what returns ```np.fft.rfft```)\n",
    "    - we store it in a matrix ```X_im``` of size ```(N/2+1, nbFrame)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C_stft:\n",
    "    \"\"\"\n",
    "    audio_v:    contains the audio signal\n",
    "    sr_hz:      sampling rate in Hz of the audio signal\n",
    "    L_sec:      analysis window length in seconds\n",
    "    STEP_sec:   analysis step in seconds\n",
    "    L_n:        analysis window length in samples\n",
    "    STEP_n:     analysis step in samples\n",
    "    LT_n:       total length of audio signal in samples\n",
    "    N:          size of the DFT\n",
    "    window_v:  contains the values of the analysis window\n",
    "    axis_freq_hz_v: frequency axis of half of the FFT in Hz (only used for plots)\n",
    "    axis_time_sec_v: time axis storing the position (in second) of the analysis window over the input signal\n",
    "    \"\"\"\n",
    "\n",
    "    audio_v = []\n",
    "    sr_hz = []\n",
    "    L_sec = 0.06\n",
    "    STEP_sec = 0.06/3\n",
    "    L_n = []\n",
    "    STEP_n = []\n",
    "    LT_n = []\n",
    "    N = []\n",
    "    window_v = []\n",
    "    axis_freq_hz_v = []\n",
    "    axis_time_sec_v = []\n",
    "\n",
    "\n",
    "    def __init__(self, audio_file):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sr_hz, self.audio_v = scipy.io.wavfile.read(audio_file) \n",
    "        self.audio_v = np.mean(self.audio_v, axis=1) / 2**16\n",
    "        \n",
    "    def __setattr__(self, attrName, val):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if hasattr(self, attrName):\n",
    "            self.__dict__[attrName] = val\n",
    "        else:\n",
    "            raise Exception(\"self.%s note part of the fields\" % attrName)\n",
    "\n",
    "    def get_stft(self):\n",
    "        \"\"\"\n",
    "        description:\n",
    "            compute the complex short-time-fourier-transform\n",
    "        outputs:\n",
    "            - X_im (N/2+1, nb_frame): complex numpy matrix which stores the complex STFT \n",
    "                (because of symetry we only keep the positive axis, hence N/2+1)\n",
    "        \"\"\"\n",
    "\n",
    "        if do_student:\n",
    "            # --- START CODE HERE\n",
    "            self.L_n = ...\n",
    "            self.STEP_n = ...\n",
    "            self.N = ...\n",
    "            nb_frame = ...\n",
    "            self.axis_freq_hz_v = ...\n",
    "            self.axis_time_sec_v = ...\n",
    "            \n",
    "            for num_frame in ... :\n",
    "                ...\n",
    "                \n",
    "            # --- END CODE HERE\n",
    "  \n",
    "        return X_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stft = C_stft(audio_file)\n",
    "# +++++++++++++++++++++++++\n",
    "F_plot1(np.arange(0, my_stft.audio_v.shape[0]), my_stft.audio_v, 'Time [sample]', 'Value')\n",
    "ipd.Audio(my_stft.audio_v, rate=my_stft.sr_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_im = my_stft.get_stft()\n",
    "\n",
    "# +++++++++++++++++++++++++\n",
    "F_plot2(F_to_log(np.abs(X_im)), my_stft.axis_freq_hz_v, my_stft.axis_time_sec_v, 'Frequency [Hz]', 'Time [sec]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-create audio signal from STFT using overlap-add method\n",
    "\n",
    "Function to write: ```F_inverse_stft```\n",
    "\n",
    "**Allocation**\n",
    "- Allocate the time vector ```hat_audio_v``` in which the progressive addition/overlapping of the audio frames will be stored\n",
    "- Allocate the time vector ```hat_window_v``` in which the progressive addition/overlap of the analysis window will be stored\n",
    "\n",
    "**Loop**\n",
    "- We create a loop through the columns (the frames) of the matrix ```X_im```.\n",
    "    - For each column we calculate its inverse DFT and keep its real part (```real(ifft())```)\n",
    "    - Truncate the resulting signal to length ```L_n```.\n",
    "    - Perform the overlap/add operation of the audio signal\n",
    "        - At which position should the signal be added?\n",
    "    - Perform the overlap/add operation of the analysis window\n",
    "\n",
    "**Normalisation**\n",
    "- Once the whole audio signal is obtained by addition/overlap, it is normalized by the overlapped/added analysis windows\n",
    "    - We will avoid division by 0 by adding the a very small value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_inverse_stft(my_stft, X_im):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        my_stft: object from class C_stft\n",
    "        X_im: complex STFT of size (N/2+1, nb_frame)\n",
    "    outputs:\n",
    "        hat_audio_v: audio signal re-created using inverse STFT (overlap-add method)\n",
    "    \"\"\"\n",
    "    \n",
    "    if do_student:\n",
    "        # --- START CODE HERE\n",
    "        hat_audio_v = ...\n",
    "        hat_window_v = ...\n",
    "        for num_frame in ... :\n",
    "            hat_signal_v = ...\n",
    "            # --- get position where to overlap and add\n",
    "            hat_audio_v += ...\n",
    "            hat_window_v += ...\n",
    "        # --- normalisation\n",
    "        \n",
    "        # --- END CODE HERE\n",
    "        \n",
    "    return hat_audio_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "We will check that the whole chain: audio -> STFT ```X_im``` -> inverse STFT.\n",
    "The output should give exactly the same audio signal as the input\n",
    "\n",
    "This can be done by superimposing the two waveforms:\n",
    "``plot(my_stft.audio_v), plot(hat_audio_v, 'r--')``.\n",
    "They should overlap perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_audio_v = F_inverse_stft(my_stft, X_im)\n",
    "\n",
    "# +++++++++++++++++++++++++\n",
    "s = 5000\n",
    "e = s + 1000\n",
    "plt.plot(my_stft.audio_v[s:e], 'k-')\n",
    "plt.plot(hat_audio_v[s:e], 'r+')\n",
    "\n",
    "ipd.Audio(hat_audio_v.squeeze(), rate=my_stft.sr_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second step: denoising the signal using spectral subtraction\n",
    "\n",
    "Function to write: ```F_denoising_spectral_subtraction.m```\n",
    "\n",
    "The audio signal ```speech_noise.wav``` contains a voice signal over crowd noise in a stadium.\n",
    "We want to denoise this signal by removing the crowd noise.\n",
    "The spectral subtraction algorithm will be used for this.\n",
    "The complex spectrogram ``X_im`` already calculated will be used for this.\n",
    "\n",
    "- The noise (crowd signal in a stadium) is present in an isolated way between the times 0.1 and 0.7~s.\n",
    "    - Question: how to find the interval of the corresponding $T$ frames of ```|X_im|``` ?\n",
    "- We will use this interval $T$ of ```|X_im|``` to calculate the noise footprint to be removed: $\\mu(\\omega) = \\mathbb{E}_{\\tau \\in T} \\{ |N(\\omega,\\tau)| \\}$\n",
    "- We will then calculate at each frame $\\tau$ the filter $H(\\omega,\\tau) = 1-\\frac{\\mu(\\omega)}{|X(\\omega,\\tau)|}$\n",
    "    - Note: one can greatly accelerate the calculation by using the matrix computation, in particular the division term-by-term or the multiplication term-by-term.\n",
    "- To avoid the negative values of the filter $H$, we will apply to each frame $\\tau$ a Half-Wave-Rectification (HWR) on $H$: $H_R(\\omega,\\tau) = \\frac{H(\\omega,\\tau) + |H(\\omega,\\tau)|}{2}$\n",
    "\n",
    "\n",
    "- The complex spectrogram ``hat_X_im`` is reconstructed by simple matrix term-by-term multiplication: ```hat_X_im = H_m .* X_im ```\n",
    "\n",
    "- The corresponding audio signal will be reconstructed with the inverse STFT algorithm developed earlier: ``F_inverse_stft``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_denoising_spectral_subtraction(my_stft, X_im, start_sec, stop_sec):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        my_stft: object from class C_stft\n",
    "        X_im: complex STFT of size (N/2+1, nb_frame)\n",
    "        start_sec, stop_sec: location over time (in second) where the noise should be captured\n",
    "    outputs:\n",
    "        hat_X_im: denoised complex STFT of size (N/2+1, nb_frame)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if do_student:\n",
    "        # --- START CODE HERE\n",
    "        mu_v = ...\n",
    "        H_m = ...\n",
    "        HR_m = ...\n",
    "        hat_X_im = ...\n",
    "        # --- END CODE HERE\n",
    " \n",
    "    return hat_X_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_X_im = F_denoising_spectral_subtraction(my_stft, X_im, 0.1, 0.7)\n",
    "denoised_audio_v = F_inverse_stft(my_stft, denoised_X_im).ravel()\n",
    "\n",
    "\n",
    "# +++++++++++++++++++++++++\n",
    "F_plot2(F_to_log(np.abs(denoised_X_im)))\n",
    "ipd.Audio(denoised_audio_v, rate=my_stft.sr_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third step: time-stretching using phase-vocoder\n",
    "\n",
    "Function to write: ```F_phase_vocoder```\n",
    "\n",
    "The phase vocoder algorithm will be used to slow down the raw signal by a value of ```alpha=0.6```.\n",
    "\n",
    "**Allocation**\n",
    "- If we note ```R_ana``` the number of analysis frames, we calculate the number of synthesis frames ```R_syn = round(R_ana/alpha)``` required for the requested ```alpha``` expansion\n",
    "- We then allocate the matrix that will contain, at each synthesis frame $r_syn$, the modified complex spectra ```hat_X_im```. It is of dimension ``(N/2+1, R_syn)``.\n",
    "\n",
    "**Loop**\n",
    "- We will then create a loop over the synthesis frames $r_{syn} \\in [0,R_{syn}[$.\n",
    "    - For a given synthesis frame ```r_syn```, the corresponding analysis frame will be calculated according to the rule of three: ```r_ana = r_syn*(R_ana-1)/(R_syn-1)```.\n",
    "    \n",
    "\n",
    "## Amplitude computation\n",
    "\n",
    "- The amplitude spectrum ```am_fft_v``` is computed as the interpolation between the analysis data at frame ```r1=floor(r_ana)``` and ```r2=r1+1```.\n",
    "\n",
    "\n",
    "## Phase computation\n",
    "\n",
    "There are three possibilities to compute the phase. Only the third one is correct, but we ask you to implement the three of them.\n",
    "\n",
    "In the three cases,\n",
    "- We get the complex spectrum at frame ``r_syn`` using the interpolated amplitude spectrum and the specific phase spectrum\n",
    "    - ```hat_X_im(:,r_syn) = am_fft_v .* exp(j * cumul_phase_v)```\n",
    "- The corresponding audio signal will be reconstructed using the inverse STFT algorithm applied to ```hat_X_im```\n",
    "\n",
    "### Solution 1 (wrong): phase spectrum equal zero\n",
    "\n",
    "- At each synthesis frame, we use a phase spectrum equal to zero ```cumul_phase_v=0```\n",
    "- Note: listening to the obtained signal we can hear a robotic signal\n",
    "- Question: How can we change the pitch of the robot ?\n",
    "    - Advanced: Try running the program again by changing the step size of the STFT ``STEP_sec``.\n",
    "\n",
    "\n",
    "### Solution 2 (wrong): phase spectrum is incremented using the theoretical frequencies\n",
    "\n",
    "- At each synthesis frame, we increment the phase spectrum ```cumul_phase_v``` using the theoretical value corresponding to each frequency $f_k$ of the spectrum.\n",
    "- As a reminder, for a STFT bin at frequency $f_k$, the theoretical model consider that the phase evolves over time as $\\Delta \\Phi = 2 \\pi f_k \\Delta t$, where $\\Delta t$ corresponds here to the hop size ```STEP_n```.\n",
    "    - Question: how do we calculate the frequencies $f_k$ in Hz of the DFT ?\n",
    "    - Question: how do we calculate $\\Delta t$ from ```STEP_n```\n",
    "- The phases will be incremented progressively during the synthesis frames. This is to ensure continuity in the evolution of the phase for each frequency\n",
    "    - ```cumul_phase_v += delta_phi_v```\n",
    "    - The initial synthesis phase (for ```r_syn=0```) is chosen to be that of the initial complex analysis spectrum (in ```r=0```)\n",
    "- Remark: when listening to the signal ``ipd.Audio(hat_audio_v, rate=my_stft.sr_hz)`` we hear a time-modulated signal\n",
    "- Question: What is the reason for this?\n",
    "\n",
    "\t\t\t\t\n",
    "\n",
    "### Solution 3 (correct): phase spectrum is incremented using the instantaneous frequencies\n",
    "\n",
    "- As we saw during the lecture, within the filter $f_k$ of the STFT we can actually observe a signal at a frequency which is different than (but close to) $f_k$. \n",
    "- To get this frequency, we need compute the instantaneous frequency $f_0$ using the phases evolution between r1 and r2 observed within the filter $f_k$.\n",
    "- To resolve the indeterminacy of $n$ (phase wrapping, see lecture), we will look for the instantaneous frequency $f_0$ which is the closest to $f_k$ using\n",
    "- This leads to\n",
    "```\n",
    "\t\tn_v = round( (phi2_v - (phi1_v + delta_phi_v)) / (2*pi))\n",
    "```\n",
    "- Question: explain how this is equivalent to finding the closest instantaneous frequency $f_0$ to $f_k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_phase_vocoder(my_stft, X_im, alpha, do_method = 3):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        - my_stft: object from class C_stft\n",
    "        - X_im: complex STFT of size (N/2+1, nb_frame)\n",
    "        - alpha: times-stretching factor (alpha<1 slow-down, alpha>1 speed-up)\n",
    "        - do_method: {1, 2, 3} defines the algorithm used to compute the synthesis phase spectrum\n",
    "    outputs:\n",
    "        - hat_X_im: modified complex STFT of size (N/2+1, new_nb_frame)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if do_student:\n",
    "        # --- START CODE HERE\n",
    "        for r_syn in ...:\n",
    "            r1 = ...\n",
    "            r2 = ...\n",
    "            am_fft_v = ...\n",
    "            hat_X_im = ...\n",
    "            if do_method == 1:\n",
    "                cumul_phase_v = ...\n",
    "            if do_method == 2:\n",
    "                cumul_phase_v = ...\n",
    "            if do_method == 3:\n",
    "                cumul_phase_v = ...\n",
    "        # --- END CODE HERE\n",
    "        \n",
    "    return hat_X_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_denoised_X_im = F_phase_vocoder(my_stft, denoised_X_im, alpha=0.6, do_method=1)\n",
    "stretched_denoised_audio_v = F_inverse_stft(my_stft, stretched_denoised_X_im).ravel()\n",
    "ipd.Audio(stretched_denoised_audio_v, rate=my_stft.sr_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_denoised_X_im = F_phase_vocoder(my_stft, denoised_X_im, alpha=0.6, do_method=2)\n",
    "stretched_denoised_audio_v = F_inverse_stft(my_stft, stretched_denoised_X_im).ravel()\n",
    "ipd.Audio(stretched_denoised_audio_v, rate=my_stft.sr_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_denoised_X_im = F_phase_vocoder(my_stft, denoised_X_im, alpha=0.6, do_method=3)\n",
    "stretched_denoised_audio_v = F_inverse_stft(my_stft, stretched_denoised_X_im).ravel()\n",
    "\n",
    "# +++++++++++++++++++++++++\n",
    "scipy.io.wavfile.write('./result.wav', my_stft.sr_hz, stretched_denoised_audio_v)\n",
    "F_plot1(np.arange(0, stretched_denoised_audio_v.shape[0]), stretched_denoised_audio_v, 'Time [sample]', 'Value')\n",
    "ipd.Audio(stretched_denoised_audio_v, rate=my_stft.sr_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
